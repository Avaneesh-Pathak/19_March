{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "\n",
    "Provide an example to illustrate its application.\n",
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "\n",
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Min-Max scaling, also known as normalization, is a data preprocessing technique used to rescale numeric features to a specific range. It transforms the values of the features to a common scale, typically between 0 and 1. The formula for Min-Max scaling is:\n",
    "\n",
    "scaled_value = (value - min_value) / (max_value - min_value)\n",
    "\n",
    "where value is the original value of the feature, min_value is the minimum value of the feature in the dataset, and max_value is the maximum value of the feature in the dataset.\n",
    "\n",
    "For example, let's say we have a dataset of housing prices with a feature \"area\" that ranges from 500 to 2000 square feet. To apply Min-Max scaling, we subtract the minimum value (500) from each value, and then divide by the range (2000 - 500 = 1500). So, if we have a house with an area of 1200 square feet, the scaled value would be (1200 - 500) / 1500 = 0.5333.\n",
    "\n",
    "Q2. The Unit Vector technique, also known as normalization or vector normalization, is another data preprocessing technique used to rescale feature vectors. It transforms the feature vector to have a length of 1 while preserving its direction. The formula for Unit Vector scaling is:\n",
    "\n",
    "scaled_vector = vector / ||vector||\n",
    "\n",
    "where vector is the original feature vector, and ||vector|| represents the Euclidean norm (magnitude) of the vector.\n",
    "\n",
    "For example, let's say we have a dataset of student performance with two features: \"math_score\" and \"english_score.\" The feature vector for a student is [math_score, english_score]. To apply Unit Vector scaling, we divide each element of the feature vector by the magnitude of the vector. So, if a student has a feature vector [80, 90], the magnitude is calculated as sqrt(80^2 + 90^2) = 116.24. The scaled vector would be [80/116.24, 90/116.24] = [0.6887, 0.7746].\n",
    "\n",
    "Q3. Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional space. It identifies the directions, called principal components, in which the data varies the most and projects the data onto these components.\n",
    "\n",
    "The steps involved in PCA are as follows:\n",
    "1. Standardize the data: Subtract the mean from each feature and divide by the standard deviation to ensure all features have a similar scale.\n",
    "2. Compute the covariance matrix: Calculate the covariance matrix of the standardized data.\n",
    "3. Compute the eigenvectors and eigenvalues: Perform eigendecomposition on the covariance matrix to obtain the eigenvectors and eigenvalues.\n",
    "4. Select the principal components: Sort the eigenvectors in decreasing order of their corresponding eigenvalues and choose the top k eigenvectors to retain.\n",
    "5. Project the data: Multiply the standardized data by the selected eigenvectors to obtain the lower-dimensional representation.\n",
    "\n",
    "For example, suppose we have a dataset with three features: \"height,\" \"weight,\" and \"age.\" PCA can be used to reduce the dimensionality of the dataset by finding the principal components that capture the most significant variation in the data.\n",
    "\n",
    "Q4. PCA can be used for feature extraction by selecting a subset of the principal components as new features. Instead of using the original features, the dataset is transformed into a lower-dimensional space represented by the selected principal components. This reduces the dimensionality of the data while preserving the most important information.\n",
    "\n",
    "For example, let's say we have a dataset with 100 features. After applying PCA, we obtain the eigenvectors and eigenvalues. We can sort the eigenvectors based on their eigenvalues and choose the top k eigenvectors. These k eigenvectors can then be used as the new features representing the dataset in a lower-dimensional space.\n",
    "\n",
    "Q5. In the context of building a recommendation system for a food delivery service, Min-Max scaling can be used to preprocess the data as follows:\n",
    "\n",
    "1. Identify the features: Determine which features from the dataset will be used for recommendation, such as price, rating, and delivery time.\n",
    "\n",
    "2. Calculate the minimum and maximum values: Find the minimum and maximum values for each feature among all the data points in the dataset.\n",
    "\n",
    "3. Apply Min-Max scaling: For each feature, use the Min-Max scaling formula to transform the values to the range of 0 to 1. This is done by subtracting the minimum value from each value and then dividing by the range (maximum value minus minimum value).\n",
    "\n",
    "4. Use the scaled features: The transformed values can now be used as input for the recommendation system. The scaled features ensure that each feature is on a consistent scale, allowing them to contribute equally during the recommendation process.\n",
    "\n",
    "Q6. In the project aimed at predicting stock prices, PCA can be used to reduce the dimensionality of the dataset as follows:\n",
    "\n",
    "1. Gather the dataset: Collect the relevant features for stock prediction, such as company financial data (e.g., revenue, earnings, debt) and market trends (e.g., stock index values, interest rates).\n",
    "\n",
    "2. Standardize the features: To ensure all features have a similar scale, standardize them by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "3. Apply PCA: Perform PCA on the standardized dataset to obtain the principal components that capture the most significant variation in the data. Determine the number of principal components to retain based on the desired level of dimensionality reduction.\n",
    "\n",
    "4. Project the data: Multiply the standardized data by the selected principal components to obtain the lower-dimensional representation of the dataset.\n",
    "\n",
    "5. Use the reduced dataset: The reduced dataset, represented by the selected principal components, can be used as input for the stock price prediction model. The dimensionality reduction helps reduce noise and computational complexity while retaining the most relevant information.\n",
    "\n",
    "Q7. To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] and transform the values to a range of -1 to 1, follow these steps:\n",
    "\n",
    "1. Find the minimum and maximum values: The minimum value in the dataset is 1, and the maximum value is 20.\n",
    "\n",
    "2. Apply the Min-Max scaling formula: For each value in the dataset, subtract the minimum value (1) and divide by the range (20 - 1 = 19). Then, multiply by the desired range (2) and subtract 1 to shift the range to -1 to 1.\n",
    "\n",
    "   - For 1: (1 - 1) / 19 * 2 - 1 = -1\n",
    "   - For 5: (5 - 1) / 19 * 2 - 1 = -0.5789\n",
    "   - For 10: (10 - 1) / 19 * 2 - 1 = -0.2632\n",
    "   - For 15: (15 - 1) / 19 * 2 - 1 = 0.0526\n",
    "   - For 20: (20 - 1) / 19 * 2 - 1 = 1\n",
    "\n",
    "The transformed values after Min-Max scaling range from -1 to 1.\n",
    "\n",
    "Q8. To perform feature extraction using PCA on the dataset with features [height, weight, age, gender, blood pressure], follow these steps:\n",
    "\n",
    "1. Standardize the dataset: Subtract the mean from each\n",
    "\n",
    "feature and divide by the standard deviation to ensure all features have a similar scale.\n",
    "\n",
    "2. Compute the covariance matrix: Calculate the covariance matrix of the standardized dataset.\n",
    "\n",
    "3. Compute the eigenvectors and eigenvalues: Perform eigendecomposition on the covariance matrix to obtain the eigenvectors and eigenvalues.\n",
    "\n",
    "4. Select the principal components: Sort the eigenvectors in decreasing order of their corresponding eigenvalues and choose the top k eigenvectors to retain. The number of principal components to retain depends on the desired level of dimensionality reduction and the amount of information preserved.\n",
    "\n",
    "5. Project the data: Multiply the standardized dataset by the selected eigenvectors to obtain the lower-dimensional representation.\n",
    "\n",
    "When deciding how many principal components to retain, a common approach is to consider the cumulative explained variance ratio. The explained variance ratio indicates the proportion of the total variance in the data explained by each principal component. By summing up the explained variance ratios, you can determine how much information is retained as you increase the number of principal components.\n",
    "\n",
    "For example, if the cumulative explained variance ratio reaches 95% with the first three principal components, you might choose to retain these three components as they capture a significant amount of information while reducing the dimensionality. However, the exact number of principal components to retain depends on the specific dataset and the trade-off between dimensionality reduction and information preservation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
